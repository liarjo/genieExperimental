{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b37e962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from typing import Any\n",
    "from pathlib import Path\n",
    "import json\n",
    "from colorama import Fore, Style \n",
    "import asyncio\n",
    "# Azure AI Agent\n",
    "from azure.ai.projects.models import (\n",
    "\n",
    "    FunctionTool\n",
    ")\n",
    "from azure.ai.projects.models import FunctionTool, ToolSet\n",
    "from typing import Any, Callable, Set, Dict, List, Optional\n",
    "#Genie imports\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.dashboards import GenieAPI\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea5a50c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print format function to print messages in different colors\n",
    "def printFormat(message:str, color: str):\n",
    "    print(f\"{color}{message}{Style.RESET_ALL}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163ebcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def ask_genie(question: str, space_id: str,workspace_client: WorkspaceClient, conversation_id: Optional[str] = None) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Asks a question to the Genie API and retrieves the response.\n",
    "\n",
    "    This function interacts with the Genie API to start or continue a conversation, \n",
    "    execute queries, and retrieve results or messages. It uses asynchronous operations \n",
    "    to handle potentially long-running tasks.\n",
    "    Parameters:\n",
    "    ----------\n",
    "    question : str\n",
    "        The question or prompt to send to the Genie API.\n",
    "    space_id : str\n",
    "        The Databricks space ID where the Genie API is hosted.\n",
    "    workspace_client : WorkspaceClient\n",
    "        The Databricks workspace client used to interact with the Genie API.\n",
    "    conversation_id : Optional[str], default=None\n",
    "        The ID of an existing conversation. If not provided, a new conversation is started.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    tuple[str, str]\n",
    "        A tuple containing:\n",
    "        - The JSON response from the Genie API as a string.\n",
    "        - The conversation ID used for the interaction.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        genie_api = GenieAPI(workspace_client.api_client)\n",
    "\n",
    "        loop = asyncio.get_running_loop()\n",
    "        if conversation_id is None:\n",
    "            initial_message = await loop.run_in_executor(None, genie_api.start_conversation_and_wait, space_id, question)\n",
    "            conversation_id = initial_message.conversation_id\n",
    "        else:\n",
    "            initial_message = await loop.run_in_executor(None, genie_api.create_message_and_wait, space_id, conversation_id, question)\n",
    "\n",
    "        query_result = None\n",
    "        if initial_message.query_result is not None:\n",
    "            query_result = await loop.run_in_executor(None, genie_api.get_message_query_result,\n",
    "                space_id, initial_message.conversation_id, initial_message.id)\n",
    "\n",
    "        message_content = await loop.run_in_executor(None, genie_api.get_message,\n",
    "            space_id, initial_message.conversation_id, initial_message.id)\n",
    "\n",
    "        \n",
    "        if query_result and query_result.statement_response:\n",
    "            results = await loop.run_in_executor(None, workspace_client.statement_execution.get_statement,\n",
    "                query_result.statement_response.statement_id)\n",
    "            \n",
    "            query_description = \"\"\n",
    "            query_query = \"\"\n",
    "            for attachment in message_content.attachments:\n",
    "                if attachment.query and attachment.query.description:\n",
    "                    query_description = attachment.query.description\n",
    "                    query_query=attachment.query.query\n",
    "                    printFormat(f\"query_description:\\n {query_query}\",Fore.GREEN)\n",
    "                    printFormat(f\"query_query:\\n {query_query}\",Fore.GREEN)\n",
    "                    break\n",
    "\n",
    "            return json.dumps({\n",
    "                \"columns\": results.manifest.schema.as_dict(),\n",
    "                \"data\": results.result.as_dict(),\n",
    "                \"query_description\": query_description,\n",
    "                \"query_query\": query_query,\n",
    "            }), conversation_id\n",
    "\n",
    "        if message_content.attachments:\n",
    "            for attachment in message_content.attachments:\n",
    "                if attachment.text and attachment.text.content:\n",
    "                    return json.dumps({\"message\": attachment.text.content}), conversation_id\n",
    "\n",
    "        return json.dumps({\"message\": message_content.content}), conversation_id\n",
    "    except Exception as e:\n",
    "        printFormat(f\"Error in ask_genie: {str(e)}\", Fore.RED)\n",
    "        return json.dumps({\"error\": \"An error occurred while processing your request.\"}), conversation_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b25b7cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query_results(answer_json: Dict) -> str:\n",
    "    \"\"\"\n",
    "    Processes the query results from the Genie API response and formats them into a readable string.\n",
    "\n",
    "    :param answer_json: The JSON response from the Genie API containing query results or messages.\n",
    "    :return: A formatted string containing the query description, results, or message.\n",
    "    \"\"\"\n",
    "   \n",
    "    response = \"\"\n",
    "    if \"query_description\" in answer_json and answer_json[\"query_description\"]:\n",
    "        response += f\"## Query Description\\n\\n{answer_json['query_description']}\\n\\n\"\n",
    "\n",
    "    if \"columns\" in answer_json and \"data\" in answer_json:\n",
    "        response += \"## Query Results\\n\\n\"\n",
    "        columns = answer_json[\"columns\"]\n",
    "        data = answer_json[\"data\"]\n",
    "        if isinstance(columns, dict) and \"columns\" in columns:\n",
    "            header = \"| \" + \" | \".join(col[\"name\"] for col in columns[\"columns\"]) + \" |\"\n",
    "            separator = \"|\" + \"|\".join([\"---\" for _ in columns[\"columns\"]]) + \"|\"\n",
    "            response += header + \"\\n\" + separator + \"\\n\"\n",
    "            for row in data[\"data_array\"]:\n",
    "                formatted_row = []\n",
    "                for value, col in zip(row, columns[\"columns\"]):\n",
    "                    if value is None:\n",
    "                        formatted_value = \"NULL\"\n",
    "                    elif col[\"type_name\"] in [\"DECIMAL\", \"DOUBLE\", \"FLOAT\"]:\n",
    "                        formatted_value = f\"{float(value):,.2f}\"\n",
    "                    elif col[\"type_name\"] in [\"INT\", \"BIGINT\", \"LONG\"]:\n",
    "                        formatted_value = f\"{int(value):,}\"\n",
    "                    else:\n",
    "                        formatted_value = str(value)\n",
    "                    formatted_row.append(formatted_value)\n",
    "                response += \"| \" + \" | \".join(formatted_row) + \" |\\n\"\n",
    "        else:\n",
    "            response += f\"Unexpected column format: {columns}\\n\\n\"\n",
    "    elif \"message\" in answer_json:\n",
    "        response += f\"{answer_json['message']}\\n\\n\"\n",
    "    else:\n",
    "        response += \"No data available.\\n\\n\"\n",
    "    if \"query_query\" in answer_json and answer_json[\"query_query\"]:\n",
    "        response += f\"## Generated Code\\n\\n```sql\\n{answer_json['query_query']}\\n```\\n\\n\"\n",
    "    return response\n",
    "\n",
    "async def askADBGenieAsync(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Call ADB Genie to ask a question about data\n",
    "    use only for database questions!\n",
    "\n",
    "    :param prompt  (str): the question to make to Genie assitante about data.\n",
    "    :return: text response to the question. \n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    theResponse = \"\"\n",
    "    try:\n",
    "        # call Genie\n",
    "        DATABRICKS_SPACE_ID = os.getenv(\"DATABRICKS_SPACE_ID\")\n",
    "        DATABRICKS_HOST = os.getenv(\"DATABRICKS_HOST\")\n",
    "        DATABRICKS_TOKEN = os.getenv(\"DATABRICKS_TOKEN\")\n",
    "        workspace_client = WorkspaceClient(\n",
    "            host=DATABRICKS_HOST,\n",
    "            token=DATABRICKS_TOKEN\n",
    "        )\n",
    "\n",
    "        print(f\"\")\n",
    "        print(f\"askDatabaseQuestions Prompt: {prompt}\")\n",
    "        print(f\"\")\n",
    "\n",
    "        theResponse = await (ask_genie(prompt, DATABRICKS_SPACE_ID, workspace_client))\n",
    "    except Exception as e:\n",
    "        # Handle any unexpected errors\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        theResponse = f\"Error: {str(e)}\"\n",
    "    return theResponse\n",
    "\n",
    "def askDatabaseQuestions(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetches the database information for the specified data.\n",
    "    use only for database questions!\n",
    "\n",
    "    :param prompt  (str): the question to make to Genie assitante about data.\n",
    "    :return: text response to the question. \n",
    "    :rtype: str\n",
    "    \"\"\"\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "    answer, new_conversation_id =  asyncio.run(askADBGenieAsync(prompt))\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06b7fc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statically defined user functions for fast reference\n",
    "user_functions: Set[Callable[..., Any]] = {\n",
    "    askDatabaseQuestions,\n",
    "\n",
    "}\n",
    "\n",
    "# Initialize agent toolset with user functions\n",
    "functions = FunctionTool(user_functions)\n",
    "myToolSet = ToolSet()\n",
    "myToolSet.add(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a6dca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agentInsructions = \"\"\"\n",
    "you are an agent that response user questions.\n",
    "for question related to date topics listes below you must  use the function askDatabaseQuestions.\n",
    "when you call the function askDatabaseQuestions, you must use the same prompt as the user question. you don't change the prompt.\n",
    "When you get the response from the function askDatabaseQuestions, you must return the response to the user as is.\n",
    "you must not change the response from the function askDatabaseQuestions.\n",
    "the topics are:\n",
    "- database schema questions\n",
    "- Driver questions\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c71c04bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existent agent, agent ID: asst_tFGbBbXlVYFEGbDR2dhaLuPA\n",
      "Created thread, thread ID: thread_3Gx8XQfPwyYuXyNO8IDWlm77\n"
     ]
    }
   ],
   "source": [
    "project_client = AIProjectClient.from_connection_string(\n",
    "    credential=DefaultAzureCredential(), conn_str=os.environ[\"PROJECT_CONNECTION_STRING\"]\n",
    ")\n",
    "\n",
    "#enable_auto_function_calls\n",
    "project_client.agents.enable_auto_function_calls(toolset=myToolSet)\n",
    "\n",
    "# Create or get an existing agent, use your own agent ID\n",
    "agent_ID=\"asst_tFGbBbXlVYFEGbDR2dhaLuPA\"\n",
    "\n",
    "try:\n",
    "    myAgent = project_client.agents.get_agent(agent_ID)\n",
    "    print(f\"Existent agent, agent ID: {myAgent.id}\")\n",
    "except Exception as e:\n",
    "    myAgent = project_client.agents.create_agent(\n",
    "        model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n",
    "        name=\"myADBGenieAgent\",\n",
    "        instructions=agentInsructions,\n",
    "        headers={\"x-ms-enable-preview\": \"true\"},\n",
    "        toolset=myToolSet\n",
    "    )\n",
    "    agent_ID = myAgent.id  # Update the agent_ID with the newly created agent's ID\n",
    "    print(f\"Created agent, agent ID: {myAgent.id}\")\n",
    "\n",
    "# Create a thread\n",
    "thread = project_client.agents.create_thread()\n",
    "print(f\"Created thread, thread ID: {thread.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ae62808",
   "metadata": {},
   "outputs": [],
   "source": [
    "def askFounfryAiAgent(string: str) -> str:\n",
    "    \"\"\"\n",
    "    Sends a user query to the Foundry AI Agent and retrieves the response.\n",
    "\n",
    "    This function interacts with the Foundry AI Agent by creating a message in a thread,\n",
    "    running the agent to process the message, and retrieving the assistant's response.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    string : str\n",
    "        The user query or prompt to send to the Foundry AI Agent.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    str\n",
    "        The response from the Foundry AI Agent. If the agent fails to process the query,\n",
    "        an error message is returned.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create a new agent message\n",
    "        message = project_client.agents.create_message(\n",
    "            thread_id=thread.id,\n",
    "            content=string,\n",
    "            role=\"user\",\n",
    "        )\n",
    "        print(f\"{Fore.GREEN}Created message, message ID: {message.id}\")\n",
    "\n",
    "        # Run the agent\n",
    "        run = project_client.agents.create_and_process_run(thread_id=thread.id, agent_id=myAgent.id,toolset=myToolSet)\n",
    "        print(f\"{Fore.GREEN}Run finished with status: {run.status}\")\n",
    "\n",
    "        if run.status == \"failed\":\n",
    "            # Check if you got \"Rate limit is exceeded.\", then you want to get more quota\n",
    "            print(f\"Run failed: {run.last_error}\")\n",
    "            return f\"Error: {run.last_error}\"\n",
    "\n",
    "        # Get messages from the thread\n",
    "        messages = project_client.agents.list_messages(thread_id=thread.id)\n",
    "       # print(f\"Messages: {messages}\")\n",
    "\n",
    "        # Get the last message from the sender\n",
    "        last_msg = messages.get_last_text_message_by_role(\"assistant\")\n",
    "        if last_msg:\n",
    "            #print(f\"{Fore.GREEN} Last Message: {last_msg.text.value}\")\n",
    "            return last_msg.text.value\n",
    "\n",
    "        return \"No response from the assistant.\"\n",
    "    except Exception as e:\n",
    "        # Handle any unexpected errors\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6efd0ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mCreated message, message ID: msg_AkH3Pq6eLxAfNj2vIIpwkkE2\n",
      "\n",
      "askDatabaseQuestions Prompt: list first 20 full drivers name. print the names list in a table and take the first name and write a poem in spanish.\n",
      "\n",
      "\u001b[31mError in ask_genie: 'AnsiFore' object has no attribute 'GREENen'\u001b[0m\n",
      "\u001b[32mRun finished with status: RunStatus.COMPLETED\n",
      "\u001b[37mAI Foundry Agent Answer:\n",
      " An error occurred while processing your request. Please try again later or verify the input and try again.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#test samples prompts\n",
    "#finalAnswwer=askFounfryAiAgent(\"list all table names in the database\")\n",
    "#finalAnswwer=askFounfryAiAgent(\"list all table names in the database. print the names list in a table and take the first name and write a poem in spanish.\")\n",
    "#finalAnswwer=askFounfryAiAgent(\"list first 3 drivers in json format\")\n",
    "#finalAnswwer=askFounfryAiAgent(\"list first 3 drivers\")\n",
    "#finalAnswwer=askFounfryAiAgent(\"show the full names of top 5 drivers and total wins that had the most ace wins in the 2024 seasson\")\n",
    "#finalAnswwer=askFounfryAiAgent(\"list first 20 full drivers name\")\n",
    "#finalAnswwer=askFounfryAiAgent(\"What is the talles building on Boston?\")\n",
    "finalAnswwer=askFounfryAiAgent(\"list first 20 full drivers name.  print the names list in a table and take the first name and write a poem in spanish.\")\n",
    "\n",
    "print(f\"{Fore.WHITE}AI Foundry Agent Answer:\\n {finalAnswwer}{Style.RESET_ALL}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genieExperimental",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
